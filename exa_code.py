from langchain_exa import ExaSearchRetriever
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda
from langchain_openai import ChatOpenAI
import os

def create_research_chain(exa_api_key: str, openai_api_key: str):
    # Initialize the search retriever
    retriever = ExaSearchRetriever(
        api_key=exa_api_key,
        k=3,  # Number of documents to retrieve
        highlights=True
    )
    
    # Create document formatting template
    document_template = """
    <source>
        <url>{url}</url>
        <highlights>{highlights}</highlights>
    </source>
    """
    document_prompt = PromptTemplate.from_template(document_template)
    
    # Create document processing chain
    document_chain = (
        RunnablePassthrough() | 
        RunnableLambda(lambda doc: {
            "highlights": doc.metadata.get("highlights", "No highlights available."),
            "url": doc.metadata.get("url", "No URL available.")
        }) | document_prompt
    )
    
    # Create retrieval chain
    retrieval_chain = (
        retriever | 
        document_chain.map() | 
        RunnableLambda(lambda docs: "\n".join(str(doc) for doc in docs))  # Convert docs to strings
    )
    
    # Create generation prompt
    generation_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a highly knowledgeable finance and stocks assistant. Your role is to provide the latest news, trends, and insights related to finance and stock markets. Use the XML-formatted context to ensure your responses are accurate and informative."),
        ("human", """
        Please respond to the following query using the provided context. Ensure your answer is well-structured, concise, and includes relevant data or statistics where applicable. Cite your sources at the end of your response for verification.

        Query: {query}
        ---
        <context>
        {context}
        </context>
        """)
        ])
    
    # Initialize LLM
    llm = ChatOpenAI(api_key=openai_api_key)
    
    chain = (
        RunnableParallel({
            "query": RunnablePassthrough(),  
            "context": retrieval_chain,  
        }) 
        | generation_prompt 
        | llm
    )

    return chain


def execute_research_query(chain, question: str):
    try:
        # Initialize response to None
        response = None
        
        # Retrieve API keys from Streamlit secrets with multiple fallback methods
        try:
            exa_api_key = st.secrets.get("news", {}).get("EXA_API_KEY", "")
            openai_api_key = st.secrets.get("news", {}).get("OPENAI_API_KEY", "")
        except Exception as secrets_error:
            print(f"Streamlit secrets error: {secrets_error}")
            exa_api_key = os.getenv("EXA_API_KEY", "")
            openai_api_key = os.getenv("OPENAI_API_KEY", "")
        
        # Validate API keys
        if not exa_api_key:
            raise ValueError("Exa API key is missing. Check Streamlit secrets or environment variables.")
        if not openai_api_key:
            raise ValueError("OpenAI API key is missing. Check Streamlit secrets or environment variables.")

        print(f"DEBUG: Executing research query for: {question}")

        # Attempt to invoke the chain
        try:
            response = chain.invoke(question)
            print("response", response)
        except Exception as invoke_error:
            print(f"Invoke error: {invoke_error}")

        # Now we can safely check if response is None
        if response is None:
            print("DEBUG: No response generated by the research chain")
            return {"output_text": "No research findings available for this query."}

        content = response.content if hasattr(response, 'content') else str(response)

        if not content or len(content.strip()) < 10:
            print("DEBUG: Generated response is too short")
            return {"output_text": "Unable to generate a meaningful response. Please try a different query."}

        return {"output_text": content}

    except Exception as e:
        print(f"CRITICAL ERROR in execute_research_query: {str(e)}")
        return {"output_text": f"An unexpected error occurred: {str(e)}. Please check your API key configuration."}


try:
    research_query = "how much did aapl go up last week?"
    exa_api_key = " "
    openai_api_key = " "
    research_chain = create_research_chain(exa_api_key, openai_api_key)
    research_result = execute_research_query(research_chain, research_query)
    print(research_result)
except Exception as e:
    print(f"DEBUG: Research query error: {str(e)}")